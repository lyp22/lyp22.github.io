---
published: true
title: 概率图模型：HMM、MEMM、CRF
category: Algorithm
tags: 
  - 概率图
layout: post
---



概率图模型学习笔记：HMM、MEMM、CRF

# 一、Preface
> 统计机器学习所有的模型（个别instant model和优化算法以及其他的特种工程知识点除外）的工作流程都是如此：
> a.训练模型参数，得到模型（由参数唯一确定），
> b.预测给定的测试数据。
> 拿这个流程去挨个学习模型，思路上会非常顺畅。
# 二、Prerequisite
## 2.1 概率图
之前刚接触CRF时，一上来试图越过一堆繁琐的概率图相关概念，不过sad to say, 这是后面的前驱知识，后面还得反过来补这个点。所以若想整体把握，系统地拿下这一块，应该还是要越过这块门槛的。 当然了，一开始只需略略快速看一篇，后面可再返过来补查。
### 2.1.1 概览
在统计概率图（probability graph models）中，参考宗成庆老师的书，是这样的体系结构（个人非常喜欢这种类型的图）：

![0](https://raw.githubusercontent.com/lyp22/lyp22.github.io/master/_posts/image/CRF/1.jpg)

在概率图模型中，数据(样本)由公式G=(V,E)建模表示：  V表示节点，即随机变量（放在此处的，可以是一个token或者一个label），具体地，用Y=(y1,y2,……,yn)  为随机变量建模，注意  现在是代表了一批随机变量（想象对应一条sequence，包含了很多的token），  P(Y)为这些随机变量的分布； E表示边，即概率依赖关系。具体咋理解，还是要在后面结合HMM或CRF的graph具体解释。


### 2.1.2 有向图 vs. 无向图
上图可以看到，贝叶斯网络（信念网络）都是有向的，马尔科夫网络无向。所以，贝叶斯网络适合为有单向依赖的数据建模，马尔科夫网络适合实体之间互相依赖的建模。具体地，他们的核心差异表现在如何求 P=(Y) ，即怎么表示 Y=(y1,y2,……,yn) 这个的联合概率。
#### 1. 有向图
对于有向图模型，这么求联合概率： 
![0](https://raw.githubusercontent.com/lyp22/lyp22.github.io/master/_posts/image/CRF/1.svg)


举个例子，对于下面的这个有向图的随机变量(注意，这个图我画的还是比较广义的)：

![0](https://raw.githubusercontent.com/lyp22/lyp22.github.io/master/_posts/image/CRF/2.jpg)

应该这样表示他们的联合概率:

![0](https://raw.githubusercontent.com/lyp22/lyp22.github.io/master/_posts/image/CRF/2.svg)

应该很好理解吧。